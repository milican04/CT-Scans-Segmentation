{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pleased-thanksgiving",
   "metadata": {},
   "source": [
    "# Segentation of Lung CT scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-prospect",
   "metadata": {},
   "source": [
    "Data used in project can be downloaded via following link: http://medicaldecathlon.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-american",
   "metadata": {},
   "source": [
    "## Intorduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-arrangement",
   "metadata": {},
   "source": [
    "The idea of this project is to take input data in the form of a CT scan of the lungs, create and train a model which will do their segmentation and find abnormalities if they exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-synthesis",
   "metadata": {},
   "source": [
    "The typical use of convolutional neural networks is on classification tasks, where the output of an image is a single class label. In the problem that we are considering, we definitely should classify CT scans, but we also need to locate abnormalities if they exist. To do that, it is necessary to assign a label to each pixel of the CT scan. Of course, we are going to have two labels: normal and abnormal. All pixels that are classified as abnormal, together construct the abnormality of the considering lungs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-sailing",
   "metadata": {},
   "source": [
    "The model will be a convolutional neural network based on the U-net architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-pledge",
   "metadata": {},
   "source": [
    "#### What is U-net architecture and why we are going to use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-fence",
   "metadata": {},
   "source": [
    "The U-net architecture, the so-called \"fully convolutional network,\" was designed in 2015. for the segmentation of biomedical images. U-Net has been successfully used in numerous studies and clinical applications for CT scan segmentation. \n",
    "\n",
    "It has a symetric structure in the shape of the letter U, and it consists of two main parts: the contracting path (coder) and the expansive path (decoder). This symmetric design of U-Net ensures a balanced extraction and reconstruction of features, leading to more accurate segmentation, which will be very useful considering the complex lung structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b49b6c-c744-43f2-a112-0eefd782c615",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b5ed27d-523c-478c-9bf0-7c42f1d75df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-helmet",
   "metadata": {},
   "source": [
    "## Data Preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b20b75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ct_to_slices(path):\n",
    "    data = nib.load(path).get_fdata()\n",
    "    [_, _, slices] = data.shape\n",
    "    \n",
    "    return [data[..., slice] for slice in range(slices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38cf9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ct_dataset_to_slices(dataset_dir, output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "    images_dir = os.path.join(output_dir, 'imagesTr')\n",
    "    labels_dir = os.path.join(output_dir, 'labelsTr')\n",
    "    os.mkdir(images_dir)\n",
    "    os.mkdir(labels_dir)\n",
    "    \n",
    "    image_paths = None\n",
    "    label_paths = None\n",
    "    \n",
    "    with open(os.path.join(dataset_dir, 'dataset.json'), 'r') as dataset_info:\n",
    "        data = json.load(dataset_info)\n",
    "        image_paths = [os.path.join(dataset_dir, scan['image']) for scan in data['training']]\n",
    "        label_paths = [os.path.join(dataset_dir, scan['label']) for scan in data['training']]\n",
    "        \n",
    "    for (i, path) in enumerate(image_paths):\n",
    "        for (j, slice) in enumerate(ct_to_slices(path)):\n",
    "            plt.imsave(os.path.join(images_dir, f'{i + 1}_{j + 1}.png'), slice, cmap='gray')\n",
    "    \n",
    "    for (i, path) in enumerate(label_paths):\n",
    "        for (j, slice) in enumerate(ct_to_slices(path)):\n",
    "            plt.imsave(os.path.join(labels_dir, f'{i + 1}_{j + 1}.png'), slice, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af68bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_ct_dataset_to_slices('Task06_Lung', 'Task06_Lung_Sliced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc45663-aa3d-4322-b433-47b2652750bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ovo ce izgledati lepse, sad je malo sve natrpano dok skontamo kako ce tacno sve izgledati, ako ti nesto smeta promeni slobodno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060bc930-a9b1-4093-9221-cf9ca1bb5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treniranje ce ver trajati duuuugo sa ovom velicinom slika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bf933d1-51f9-47b7-96b3-cdf2f78087d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size (width, height): (512, 512)\n",
      "Number of channels: 4\n"
     ]
    }
   ],
   "source": [
    "# load first image\n",
    "image = Image.open('Task06_Lung_Sliced/imagesTr/1_1.png')\n",
    "# image.show()\n",
    "\n",
    "print(f\"Image size (width, height): {image.size}\")\n",
    "num_channels = len(image.mode)\n",
    "print(f\"Number of channels: {num_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73044be-e4b5-4822-b91c-82544790f88f",
   "metadata": {},
   "source": [
    "Global variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e5f6674-4f2e-4064-a2ea-e1aaf0a0dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = image.size[0]\n",
    "IMG_HEIGHT = image.size[1]\n",
    "IMG_CHANNELS = num_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-first",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa200f2-d090-4dd2-a821-edb70fe78fc1",
   "metadata": {},
   "source": [
    "### U-Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20d1bcfa-5a7d-45fa-a0f7-b3de3ee1f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mislila sam da kada skontamo koje cemo dimenzije filtera itd da napravim ovakvu sliku za nasu arhitekturu i ubcaim ovako ako se slazes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe42eb9-2c83-4862-ba0e-39fb3ae15134",
   "metadata": {},
   "source": [
    "<img src=\"metadata/u-net-architecture.png\" alt=\"Alt Text\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebd7a1ef-0c6b-4535-969e-c2c204413135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ovde sam rendom stavila neke brojke koje sam nasla na netu, podesicemo posle tacno sta zelimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dec0bb3-3561-40da-973f-622b70c899d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# razlika izmedju tensorflow-a i torcha je sto ovde imamo ovu forward fju kojom definisemo \"kretanje\" izmedju slojeva, \n",
    "# nije sve u jednoj liniji kao za tensorflow\n",
    "# mozda ima i drugi nacin, ja sam nasla ovaj, ako ti se ne svidja mozemo da promenimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8776cb9e-d4db-4d91-a7d0-d963a8a9fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: opciona funkcija za crtanje izmedju slojeva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b1d38-767f-4b10-9fed-1a51cad8179d",
   "metadata": {},
   "source": [
    "Creating U-Net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "removable-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model class\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Coder\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv1_drop = nn.Dropout(0.1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv2_drop = nn.Dropout(0.1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3_drop = nn.Dropout(0.2)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4_drop = nn.Dropout(0.2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv5_drop = nn.Dropout(0.3)\n",
    "        \n",
    "        # Max pooling layers\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.upconv3 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.upconv4 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(16, 1, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Coder\n",
    "        c1 = F.relu(self.conv1(x))\n",
    "        c1 = F.relu(self.conv1_drop(self.conv1(c1)))\n",
    "        p1 = self.pool(c1)\n",
    "        \n",
    "        c2 = F.relu(self.conv2(p1))\n",
    "        c2 = F.relu(self.conv2_drop(self.conv2(c2)))\n",
    "        p2 = self.pool(c2)\n",
    "        \n",
    "        c3 = F.relu(self.conv3(p2))\n",
    "        c3 = F.relu(self.conv3_drop(self.conv3(c3)))\n",
    "        p3 = self.pool(c3)\n",
    "        \n",
    "        c4 = F.relu(self.conv4(p3))\n",
    "        c4 = F.relu(self.conv4_drop(self.conv4(c4)))\n",
    "        p4 = self.pool(c4)\n",
    "        \n",
    "        c5 = F.relu(self.conv5(p4))\n",
    "        c5 = F.relu(self.conv5_drop(self.conv5(c5)))\n",
    "        \n",
    "        # Decoder\n",
    "        u6 = self.upconv1(c5)\n",
    "        u6 = torch.cat([u6, c4], dim=1)\n",
    "        c6 = F.relu(self.conv4(u6))\n",
    "        c6 = F.relu(self.conv4_drop(self.conv4(c6)))\n",
    "\n",
    "        u7 = self.upconv2(c6)\n",
    "        u7 = torch.cat([u7, c3], dim=1)\n",
    "        c7 = F.relu(self.conv3(u7))\n",
    "        c7 = F.relu(self.conv3_drop(self.conv3(c7)))\n",
    "\n",
    "        u8 = self.upconv3(c7)\n",
    "        u8 = torch.cat([u8, c2], dim=1)\n",
    "        c8 = F.relu(self.conv2(u8))\n",
    "        c8 = F.relu(self.conv2_drop(self.conv2(c8)))\n",
    "\n",
    "        u9 = self.upconv4(c8)\n",
    "        u9 = torch.cat([u9, c1], dim=1)\n",
    "        c9 = F.relu(self.conv1(u9))\n",
    "        c9 = F.relu(self.conv1_drop(self.conv1(c9)))\n",
    "\n",
    "        output = torch.sigmoid(self.final_conv(c9))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a7bc4e3-28ff-4010-b5d4-9bbde83ca191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1_drop): Dropout(p=0.1, inplace=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_drop): Dropout(p=0.1, inplace=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_drop): Dropout(p=0.2, inplace=False)\n",
      "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_drop): Dropout(p=0.2, inplace=False)\n",
      "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_drop): Dropout(p=0.3, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (upconv1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (upconv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (upconv3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (upconv4): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (final_conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model instantiation\n",
    "model = UNet()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-branch",
   "metadata": {},
   "source": [
    "## Model evaluation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-consultation",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-moral",
   "metadata": {},
   "source": [
    "1. U-Net: Convolutional Networks for Biomedical Image Segmentation: Olaf Ronneberger, Philipp Fischer, and Thomas Brox - Computer Science Department and BIOSS Centre for Biological Signalling Studies, University of Freiburg, Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-shape",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
