{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1524fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac77153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ct_to_slices(path):\n",
    "    \"\"\"\n",
    "    Expects the path to a CT scan in the NIfTI format (nii.gz).\n",
    "    Returns a list of CT slices for that scan in the form of numpy arrays.\n",
    "    \"\"\"\n",
    "    data = nib.load(path).get_fdata()\n",
    "    [_, _, slices] = data.shape\n",
    "    \n",
    "    return [data[..., slice] for slice in range(slices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0586200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hounsfield(slices):\n",
    "    \"\"\"\n",
    "    Returns the minimum and maximum Hounsfield value for the passed CT scan slice.\n",
    "    \"\"\"\n",
    "    hounsfield_min = min([np.min(slice) for slice in slices])\n",
    "    hounsfield_max = max([np.max(slice) for slice in slices])\n",
    "    \n",
    "    return hounsfield_min, hounsfield_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af534468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_slice(slice, hounsfield_min, hounsfield_max):\n",
    "    \"\"\"\n",
    "    Normalizes data on the Hounsfield scale to a [0, 1] interval.\n",
    "    \"\"\"\n",
    "    slice[slice < hounsfield_min] = hounsfield_min\n",
    "    slice[slice > hounsfield_max] = hounsfield_max\n",
    "    slice = (slice - hounsfield_min) / (hounsfield_max - hounsfield_min)\n",
    "    \n",
    "    return slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009c099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ct_dataset_to_slices(dataset_dir, output_dir, negative_downsampling_rate=1, positive_downsampling_rate=1):\n",
    "    \"\"\"\n",
    "    Converts a Medical Segmentation Decathlon CT scan training dataset to\n",
    "    the sliced images form, with optional downsampling of negative (no tumors present)\n",
    "    or positive (with tumors present) slices.\n",
    "    \n",
    "    The slices are represented as single channel grayscale .png images.\n",
    "    \"\"\"\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "    images_dir = os.path.join(output_dir, 'images')\n",
    "    labels_dir = os.path.join(output_dir, 'labels')\n",
    "    os.mkdir(images_dir)\n",
    "    os.mkdir(labels_dir)\n",
    "    \n",
    "    image_paths = None\n",
    "    label_paths = None\n",
    "    \n",
    "    with open(os.path.join(dataset_dir, 'dataset.json'), 'r') as dataset_info:\n",
    "        data = json.load(dataset_info)\n",
    "        image_paths = [os.path.join(dataset_dir, scan['image']) for scan in data['training']]\n",
    "        label_paths = [os.path.join(dataset_dir, scan['label']) for scan in data['training']]\n",
    "        \n",
    "    for i in range(len(label_paths)):\n",
    "        label_path = label_paths[i]\n",
    "        image_path = image_paths[i]\n",
    "        \n",
    "        label_slices = ct_to_slices(label_path)\n",
    "        image_slices = ct_to_slices(image_path)\n",
    "        \n",
    "        hounsfield_min, hounsfield_max = calc_hounsfield(image_slices)\n",
    "        \n",
    "        for j in range(len(label_slices)):\n",
    "            label_slice = label_slices[j]\n",
    "            image_slice = image_slices[j]\n",
    "            \n",
    "            # Check if the slice contains any traces of tumors\n",
    "            if 1.0 not in label_slice:\n",
    "                if random.random() > 1 / negative_downsampling_rate:\n",
    "                    continue\n",
    "            else:\n",
    "                if random.random() > 1 / positive_downsampling_rate:\n",
    "                    continue\n",
    "                \n",
    "            label_slice = label_slice * 255\n",
    "            image_slice = normalize_slice(image_slice, hounsfield_min, hounsfield_max) * 255\n",
    "            \n",
    "            Image.fromarray(label_slice).convert('L').save(os.path.join(labels_dir, f'{i + 1}_{j + 1}.png'))\n",
    "            Image.fromarray(image_slice).convert('L').save(os.path.join(images_dir, f'{i + 1}_{j + 1}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2519953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(sliced_dataset_dir, train_dataset_dir, val_dataset_dir, test_dataset_dir, val_split=0.2, test_split=0.2):\n",
    "    \"\"\"\n",
    "    Splits a dataset (obtained by a call to convert_ct_dataset_to_slices) into\n",
    "    a train, validation and test subset.\n",
    "    \n",
    "    Due to the Medical Segmentation Decathlon test dataset labels (ground truths) not being provided,\n",
    "    we'll have to use part of the set they provided for training as our testing set.\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(sliced_dataset_dir, 'images')\n",
    "    labels_dir = os.path.join(sliced_dataset_dir, 'labels')\n",
    "    \n",
    "    image_paths = next(os.walk(images_dir))[2]\n",
    "    scan_ids = set([path.split('_')[0] for path in image_paths])\n",
    "    \n",
    "    num_val = int(len(scan_ids) * val_split)\n",
    "    num_test = int(len(scan_ids) * test_split)\n",
    "    \n",
    "    val_scans = set(random.sample(sorted(scan_ids), num_val))\n",
    "    test_scans = set(random.sample(sorted(scan_ids.difference(val_scans)), num_test))\n",
    "    \n",
    "    train_images_dir = os.path.join(train_dataset_dir, 'images')\n",
    "    train_labels_dir = os.path.join(train_dataset_dir, 'labels')\n",
    "    \n",
    "    val_images_dir = os.path.join(val_dataset_dir, 'images')\n",
    "    val_labels_dir = os.path.join(val_dataset_dir, 'labels')\n",
    "    \n",
    "    test_images_dir = os.path.join(test_dataset_dir, 'images')\n",
    "    test_labels_dir = os.path.join(test_dataset_dir, 'labels')\n",
    "    \n",
    "    os.makedirs(train_images_dir)\n",
    "    os.makedirs(train_labels_dir)\n",
    "    \n",
    "    os.makedirs(val_images_dir)\n",
    "    os.makedirs(val_labels_dir)\n",
    "    \n",
    "    os.makedirs(test_images_dir)\n",
    "    os.makedirs(test_labels_dir)\n",
    "    \n",
    "    for path in image_paths:\n",
    "        scan_id = path.split('_')[0]\n",
    "        if scan_id in val_scans:\n",
    "            os.rename(os.path.join(images_dir, path), os.path.join(val_images_dir, path))\n",
    "            os.rename(os.path.join(labels_dir, path), os.path.join(val_labels_dir, path))\n",
    "        elif scan_id in test_scans:\n",
    "            os.rename(os.path.join(images_dir, path), os.path.join(test_images_dir, path))\n",
    "            os.rename(os.path.join(labels_dir, path), os.path.join(test_labels_dir, path))\n",
    "        else:\n",
    "            os.rename(os.path.join(images_dir, path), os.path.join(train_images_dir, path))\n",
    "            os.rename(os.path.join(labels_dir, path), os.path.join(train_labels_dir, path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
