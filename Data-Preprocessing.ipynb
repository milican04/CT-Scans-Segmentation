{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9497179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628d0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ct_to_slices(path):\n",
    "    \"\"\"\n",
    "    Expects the path to a CT scan in the NIfTI format (nii.gz).\n",
    "    Returns a list of CT slices for that scan in the form of numpy arrays.\n",
    "    \"\"\"\n",
    "    data = nib.load(path).get_fdata()\n",
    "    [_, _, slices] = data.shape\n",
    "    \n",
    "    return [data[..., slice] for slice in range(slices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d36de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hounsfield(slices):\n",
    "    \"\"\"\n",
    "    Returns the minimum and maximum Hounsfield value for the passed CT scan slice.\n",
    "    \"\"\"\n",
    "    hounsfield_min = min([np.min(slice) for slice in slices])\n",
    "    hounsfield_max = max([np.max(slice) for slice in slices])\n",
    "    \n",
    "    return hounsfield_min, hounsfield_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f2b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_slice(slice, hounsfield_min, hounsfield_max):\n",
    "    \"\"\"\n",
    "    Normalizes data on the Hounsfield scale to a [0, 1] interval.\n",
    "    \"\"\"\n",
    "    slice[slice < hounsfield_min] = hounsfield_min\n",
    "    slice[slice > hounsfield_max] = hounsfield_max\n",
    "    slice = (slice - hounsfield_min) / (hounsfield_max - hounsfield_min)\n",
    "    \n",
    "    return slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d39ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ct_dataset_to_slices(dataset_dir, train_dir, val_dir, test_dir, val_split=0.2, test_split=0.2, negative_downsampling_rate=1, positive_downsampling_rate=1):\n",
    "    \"\"\"\n",
    "    Converts a Medical Segmentation Decathlon CT scan training dataset to\n",
    "    the sliced images form, with optional downsampling of negative (no tumors present)\n",
    "    or positive (with tumors present) slices in the training set.\n",
    "    \n",
    "    The slices are represented as single channel grayscale .png images.\n",
    "    \n",
    "    Due to the Medical Segmentation Decathlon test dataset labels (ground truths) not being provided,\n",
    "    we'll have to use parts of the set they provided for training as our validation and testing sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_images = os.path.join(train_dir, 'images')\n",
    "    train_labels = os.path.join(train_dir, 'labels')\n",
    "    \n",
    "    val_images = os.path.join(val_dir, 'images')\n",
    "    val_labels = os.path.join(val_dir, 'labels')\n",
    "    \n",
    "    test_images = os.path.join(test_dir, 'images')\n",
    "    test_labels = os.path.join(test_dir, 'labels')\n",
    "    \n",
    "    os.makedirs(train_images)\n",
    "    os.makedirs(train_labels)\n",
    "    \n",
    "    os.makedirs(val_images)\n",
    "    os.makedirs(val_labels)\n",
    "    \n",
    "    os.makedirs(test_images)\n",
    "    os.makedirs(test_labels)\n",
    "    \n",
    "    image_paths = None\n",
    "    label_paths = None\n",
    "    \n",
    "    with open(os.path.join(dataset_dir, 'dataset.json'), 'r') as dataset_info:\n",
    "        data = json.load(dataset_info)\n",
    "        image_paths = [os.path.join(dataset_dir, scan['image']) for scan in data['training']]\n",
    "        label_paths = [os.path.join(dataset_dir, scan['label']) for scan in data['training']]\n",
    "    \n",
    "    num_of_scans = len(image_paths)\n",
    "    num_val = int(num_of_scans * val_split)\n",
    "    num_test = int(num_of_scans * test_split)\n",
    "    \n",
    "    scan_ids = set(range(num_of_scans))\n",
    "    val_scans = set(random.sample(sorted(scan_ids), num_val))\n",
    "    test_scans = set(random.sample(sorted(scan_ids.difference(val_scans)), num_test))\n",
    "    \n",
    "    for i in range(len(label_paths)):\n",
    "        target_images_dir = None\n",
    "        target_labels_dir = None\n",
    "        \n",
    "        is_in_train = False\n",
    "        \n",
    "        if i in val_scans:\n",
    "            target_images_dir = val_images\n",
    "            target_labels_dir = val_labels\n",
    "        elif i in test_scans:\n",
    "            target_images_dir = test_images\n",
    "            target_labels_dir = test_labels\n",
    "        else:\n",
    "            target_images_dir = train_images\n",
    "            target_labels_dir = train_labels\n",
    "            is_in_train = True\n",
    "        \n",
    "        label_slices = ct_to_slices(label_paths[i])\n",
    "        image_slices = ct_to_slices(image_paths[i])\n",
    "        \n",
    "        hounsfield_min, hounsfield_max = calc_hounsfield(image_slices)\n",
    "        \n",
    "        for j in range(len(label_slices)):\n",
    "            image_slice = image_slices[j]\n",
    "            label_slice = label_slices[j]\n",
    "            \n",
    "            # Downsample only for the training set\n",
    "            if is_in_train:\n",
    "                # Check if the slice contains any traces of tumors\n",
    "                if 1.0 not in label_slice:\n",
    "                    if random.random() > 1 / negative_downsampling_rate:\n",
    "                        continue\n",
    "                else:\n",
    "                    if random.random() > 1 / positive_downsampling_rate:\n",
    "                        continue\n",
    "            \n",
    "            image_slice = normalize_slice(image_slice, hounsfield_min, hounsfield_max) * 255\n",
    "            label_slice = label_slice * 255\n",
    "            \n",
    "            Image.fromarray(image_slice).convert('L').save(os.path.join(target_images_dir, f'{i + 1}_{j + 1}.png'))\n",
    "            Image.fromarray(label_slice).convert('L').save(os.path.join(target_labels_dir, f'{i + 1}_{j + 1}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa156ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, image_transform=None, label_transform=None):\n",
    "        image_names = sorted(os.listdir(image_dir))\n",
    "        self.image_paths = [os.path.join(image_dir, image_name) for image_name in image_names]\n",
    "        \n",
    "        label_names = sorted(os.listdir(label_dir))\n",
    "        self.label_paths = [os.path.join(label_dir, label_name) for label_name in label_names]\n",
    "        \n",
    "        self.image_transform = image_transform\n",
    "        self.label_transform = label_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = read_image(self.image_paths[idx])\n",
    "        label = read_image(self.label_paths[idx])\n",
    "        \n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        if self.label_transform:\n",
    "            label = self.label_transform(label)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65752238-73c3-4e65-b856-aef9415ae4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDatasetMultiSlices(Dataset):\n",
    "    def __init__(self, root_dir, image_transform=None, label_transform=None):\n",
    "        self.image_transform = image_transform\n",
    "        self.label_transform = label_transform\n",
    "\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        images_root = os.path.join(root_dir, 'images')\n",
    "        labels_root = os.path.join(root_dir, 'labels')\n",
    "\n",
    "        image_files = image_files = sorted(os.listdir(images_root), key=numerical_sort)\n",
    "        label_files = image_files = sorted(os.listdir(labels_root), key=numerical_sort)\n",
    "\n",
    "        # Group image and label files by scan ID\n",
    "        scan_slices = {}\n",
    "        for img_file, lbl_file in zip(image_files, label_files):\n",
    "            scan_id = img_file.split('_')[0]\n",
    "            if scan_id not in scan_slices:\n",
    "                scan_slices[scan_id] = []\n",
    "            scan_slices[scan_id].append((img_file, lbl_file))\n",
    "\n",
    "        # Merge slices into 3-channel images and store them\n",
    "        for scan_id, slices in scan_slices.items():\n",
    "            for i in range(len(slices)):\n",
    "                curr_img_file, curr_lbl_file = slices[i]\n",
    "\n",
    "                # Determine previous and next slices using the list index\n",
    "                prev_img_file = slices[i-1][0] if i > 0 else curr_img_file\n",
    "                next_img_file = slices[i+1][0] if i < len(slices) - 1 else curr_img_file\n",
    "\n",
    "                # Load images\n",
    "                prev_image = read_image(os.path.join(images_root, prev_img_file))\n",
    "                curr_image = read_image(os.path.join(images_root, curr_img_file))\n",
    "                next_image = read_image(os.path.join(images_root, next_img_file))\n",
    "\n",
    "                # Stack images into a 3-channel tensor\n",
    "                image_3ch = torch.cat([prev_image, curr_image, next_image], dim=0)\n",
    "\n",
    "                # Load label\n",
    "                label = read_image(os.path.join(labels_root, curr_lbl_file))\n",
    "\n",
    "                # Store the merged image and label\n",
    "                self.images.append(image_3ch)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        if self.label_transform:\n",
    "            label = self.label_transform(label)\n",
    "\n",
    "        return image, label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
